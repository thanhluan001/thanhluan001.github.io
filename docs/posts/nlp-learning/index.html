<!DOCTYPE html>
<html lang='en' dir='auto'><head>
  <meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='description' content='We follow a NLP tutorial with code today (this link)
Getting Data We&rsquo;re using &ldquo;Disasters in Social Media&rdquo; dataset which consists of tweet archive where
 Over 10,000 tweets culled with a variety of searches like “ablaze”, “quarantine”, and “pandemonium”, then noted whether the tweet referred to a disaster event (as opposed to a joke with the word or a movie review or something non-disastrous).
 The objective is to distinguish between tweets that signal disasters and &ldquo;irrelevant&rdquo; tweets.'>
<meta name='theme-color' content='#ffcd00'>

<meta property='og:title' content='Nlp Learning with tutorial and code (part 1) • Luan Pham'>
<meta property='og:description' content='We follow a NLP tutorial with code today (this link)
Getting Data We&rsquo;re using &ldquo;Disasters in Social Media&rdquo; dataset which consists of tweet archive where
 Over 10,000 tweets culled with a variety of searches like “ablaze”, “quarantine”, and “pandemonium”, then noted whether the tweet referred to a disaster event (as opposed to a joke with the word or a movie review or something non-disastrous).
 The objective is to distinguish between tweets that signal disasters and &ldquo;irrelevant&rdquo; tweets.'>
<meta property='og:url' content='http://www.example.com/posts/nlp-learning/'>
<meta property='og:site_name' content='Le Metro'>
<meta property='og:type' content='article'><meta property='og:image' content='https://www.gravatar.com/avatar/c56c507da2d28ce01829625ce03637ac?s=256'><meta property='article:section' content='posts'><meta property='article:tag' content='NLP'><meta property='article:tag' content='Deep Learning'><meta property='article:tag' content='Machine Learning'><meta property='article:published_time' content='2020-11-05T23:18:50&#43;01:00'/><meta property='article:modified_time' content='2020-11-06T02:45:03&#43;01:00'/><meta name='twitter:card' content='summary'>

<meta name="generator" content="Hugo 0.77.0" />

  <title>Nlp Learning with tutorial and code (part 1) • Luan Pham</title>
  <link rel='canonical' href='http://www.example.com/posts/nlp-learning/'>
  
  
  <link rel='icon' href='/favicon.ico'>
<link rel='stylesheet' href='/assets/css/main.ab98e12b.css'><link rel='stylesheet' href='/css/custom.css'><style>
:root{--color-accent:#ffcd00;}
</style>

  

</head>
<body class='page type-posts has-sidebar'>

  <div class='site'><div id='sidebar' class='sidebar'>
  <a class='screen-reader-text' href='#main-menu'>Skip to Main Menu</a>

  <div class='container'><section class='widget widget-about sep-after'>
  <header>
    
    <div class='logo'>
      <a href='/'>
        <img src='/images/logo.png'>
      </a>
    </div>
    
    <h2 class='title site-title '>
      <a href='/'>
      Le Metro
      </a>
    </h2>
    <div class='desc'>
    A peek into a wandering mind :)
    </div>
  </header>

</section>
<section class='widget widget-sidebar_menu sep-after'>

  <nav id='sidebar-menu' class='menu sidebar-menu' aria-label='Sidebar Menu'>
    <div class='container'>
      <ul><li class='item'>
  <a href='/'>Home</a></li><li class='item'>
  <a href='/posts/'>Blogs</a></li><li class='item'>
  <a href='/todo/'>ToDo</a></li><li class='item'>
  <a href='/typography/'>Typography</a></li><li class='item'>
  <a href='/about/'>About</a></li></ul>
    </div>
  </nav>

</section><section class='widget widget-search sep-after'>
  <header>
    <h4 class='title widget-title'>Search</h4>
  </header>

  <form action='/search' id='search-form' class='search-form'>
    <label>
      <span class='screen-reader-text'>Search</span>
      <input id='search-term' class='search-term' type='search' name='q' placeholder='Search&hellip;'>
    </label></form>

</section>
<section class='widget widget-taxonomy_cloud sep-after'>
  <header>
    <h4 class='title widget-title'>Tags</h4>
  </header>

  <div class='container list-container'>
  <ul class='list taxonomy-cloud'><li>
        <a href='/tags/cuda/' style='font-size:1em'>Cuda</a>
      </li><li>
        <a href='/tags/deep-learning/' style='font-size:2em'>Deep Learning</a>
      </li><li>
        <a href='/tags/helloworld/' style='font-size:1em'>helloworld</a>
      </li><li>
        <a href='/tags/installation/' style='font-size:1em'>Installation</a>
      </li><li>
        <a href='/tags/machine-learning/' style='font-size:1em'>Machine Learning</a>
      </li><li>
        <a href='/tags/nlp/' style='font-size:1em'>NLP</a>
      </li></ul>
</div>


</section>
</div>

  <div class='sidebar-overlay'></div>
</div><div class='main'><a class='screen-reader-text' href='#content'>Skip to Content</a>

<button id='sidebar-toggler' class='sidebar-toggler' aria-controls='sidebar'>
  <span class='screen-reader-text'>Toggle Sidebar</span>
  <span class='open'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
  <line x1="3" y1="12" x2="21" y2="12" />
  <line x1="3" y1="6" x2="21" y2="6" />
  <line x1="3" y1="18" x2="21" y2="18" />

</svg>
</span>
  <span class='close'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
  <line x1="18" y1="6" x2="6" y2="18" />
  <line x1="6" y1="6" x2="18" y2="18" />

</svg>
</span>
</button><div class='header-widgets'>
        <div class='container'>
    
    <style>.widget-breadcrumbs li:after{content:'\2f '}</style>
  <section class='widget widget-breadcrumbs sep-after'>
    <nav id='breadcrumbs'>
      <ol><li><a href='/'>Home</a></li><li><a href='/posts/'>Blogs</a></li><li><span>Nlp Learning with tutorial and code (part 1)</span></li></ol>
    </nav>
  </section></div>
      </div>

      <header id='header' class='header site-header'>
        <div class='container sep-after'>
          <div class='header-info'><p class='site-title title'>Le Metro</p>            
          </div>
        </div>
      </header>

      <main id='content'>


<article lang='en' class='entry'>
  <header class='header entry-header'>
  <div class='container sep-after'>
    <div class='header-info'>
      <h1 class='title'>Nlp Learning with tutorial and code (part 1)</h1>
      

    </div>
    <div class='entry-meta'>
  <span class='posted-on'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"/>
  <line x1="16" y1="2" x2="16" y2="6"/>
  <line x1="8" y1="2" x2="8" y2="6"/>
  <line x1="3" y1="10" x2="21" y2="10"/>

</svg>
<span class='screen-reader-text'>Posted on </span>
  <time class='entry-date' datetime='2020-11-05T23:18:50&#43;01:00'>2020, Nov 05</time>
</span>

  <span class='byline'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
  <path d="M21,21V20c0-2.76-4-5-9-5s-9,2.24-9,5v1"/>
  <path d="M16,6.37A4,4,0,1,1,12.63,3,4,4,0,0,1,16,6.37Z"/>

</svg>
<span class='screen-reader-text'> by </span><a href='/authors/luanpham'>Luan Pham</a></span>
  
<span class='reading-time'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
  <circle cx="12" cy="12" r="10"/>
  <polyline points="12 6 12 12 15 15"/>

</svg>
6 mins read
</span>


</div>


  </div>
</header>

  
  

  <div class='container entry-content'>
  <p>We follow a NLP tutorial with code today (<a href="https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e">this link</a>)</p>
<h2 id="getting-data">Getting Data</h2>
<p>We&rsquo;re using &ldquo;Disasters in Social Media&rdquo; dataset which consists  of tweet archive where</p>
<blockquote>
<p>Over 10,000 tweets culled with a variety of
searches like “ablaze”, “quarantine”, and “pandemonium”, then
noted whether the tweet referred to a disaster event (as opposed
to a joke with the word or a movie review or something
non-disastrous).</p>
</blockquote>
<p>The objective is to distinguish between tweets that signal disasters and &ldquo;irrelevant&rdquo; tweets.</p>
<h2 id="process-data">Process Data</h2>
<h4 id="1-show-data">1. Show Data</h4>
<p>A sample of the data:</p>
<pre><code class="language-csv" data-lang="csv">        text	choose_one	class_label
0	Just happened a terrible car crash	Relevant	1
1	Our Deeds are the Reason of this #earthquake M...	Relevant	1
2	Heard about #earthquake is different cities, s...	Relevant	1
3	there is a forest fire at spot pond, geese are...	Relevant	1
4	Forest fire near La Ronge Sask. Canada	Relevant	1
5	All residents asked to 'shelter in place' are ...	Relevant	1
6	13,000 people receive #wildfires evacuation or...	Relevant	1
7	Just got sent this photo from Ruby #Alaska as ...	Relevant	1
8	#RockyFire Update =&gt; California Hwy. 20 closed...	Relevant	1
9	Apocalypse lighting. #Spokane #wildfires	Relevant	1
</code></pre><h4 id="2-clean-data">2. Clean Data</h4>
<p>Firstly, we to clean some data and replace all the extranious tokens with empty string <code>&quot;&quot;</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># questions is the dataset loaded with pandas</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">standardize_text</span>(df, text_field):
    df[text_field] <span style="color:#f92672">=</span> df[text_field]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;http\S+&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>)
    df[text_field] <span style="color:#f92672">=</span> df[text_field]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;http&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>)
    df[text_field] <span style="color:#f92672">=</span> df[text_field]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;@\S+&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>)
    df[text_field] <span style="color:#f92672">=</span> df[text_field]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;[^A-Za-z0-9(),!?@\&#39;\`</span><span style="color:#ae81ff">\&#34;</span><span style="color:#e6db74">\_\n]&#34;</span>, <span style="color:#e6db74">&#34; &#34;</span>)
    df[text_field] <span style="color:#f92672">=</span> df[text_field]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;@&#34;</span>, <span style="color:#e6db74">&#34;at&#34;</span>)
    df[text_field] <span style="color:#f92672">=</span> df[text_field]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>lower()
    <span style="color:#66d9ef">return</span> df

questions <span style="color:#f92672">=</span> standardize_text(questions, <span style="color:#e6db74">&#34;text&#34;</span>)

questions<span style="color:#f92672">.</span>to_csv(<span style="color:#e6db74">&#34;clean_data.csv&#34;</span>)
questions<span style="color:#f92672">.</span>head()
</code></pre></div><h4 id="3-tokenize-data">3. Tokenize Data</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> RegexpTokenizer

tokenizer <span style="color:#f92672">=</span> RegexpTokenizer(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\w+&#39;</span>)

clean_questions[<span style="color:#e6db74">&#34;tokens&#34;</span>] <span style="color:#f92672">=</span> clean_questions[<span style="color:#e6db74">&#34;text&#34;</span>]<span style="color:#f92672">.</span>apply(tokenizer<span style="color:#f92672">.</span>tokenize)
</code></pre></div><p>Here we tokenizer by words separated by space <code>r'\w+'</code></p>
<h2 id="actual-machine-learning-d">Actual Machine Learning :D</h2>
<h4 id="bag-of-words-count">Bag of Words Count</h4>
<p>The simplest approach we can start with is to use a bag of words model, and apply a logistic regression on top. A bag of words just associates an index to each word in our vocabulary, and embeds each sentence as a list of 0s, with a 1 at each index corresponding to a word present in the sentence.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
<span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer, TfidfVectorizer

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cv</span>(data):
    count_vectorizer <span style="color:#f92672">=</span> CountVectorizer()
    emb <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>fit_transform(data)
    <span style="color:#66d9ef">return</span> emb, count_vectorizer

list_corpus <span style="color:#f92672">=</span> clean_questions[<span style="color:#e6db74">&#34;text&#34;</span>]<span style="color:#f92672">.</span>tolist()
list_labels <span style="color:#f92672">=</span> clean_questions[<span style="color:#e6db74">&#34;class_label&#34;</span>]<span style="color:#f92672">.</span>tolist()

X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(list_corpus, 
                            list_labels, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">40</span>)

X_train_counts, count_vectorizer <span style="color:#f92672">=</span> cv(X_train)
X_test_counts <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</code></pre></div><p><code>X_train_counts</code> is the new embeding with each word embeded in a vector of 15928 length (more info at this <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">link</a>). This approach totally ignores the order of words in our sentences.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X_train_counts<span style="color:#f92672">.</span>get_shape()
(<span style="color:#ae81ff">8687</span>, <span style="color:#ae81ff">15928</span>)
</code></pre></div><h4 id="visualize-the-embedding">Visualize the embedding</h4>
<p>Normally we need to reduce the dimension of the embedding to graph</p>
<div style="text-align: center;">
    <img src="/images/nlp_embed_visualize.png" alt=""  style="width: 550px;" />
    <p style="font-size: 15px;">Bag of Words visualization</p>
</div>
<br />
<p>As shown in the image, there is no distinguishing features between the Irrelevant and Disaster class because the vector from Bag of Word algorithm was initialized randomly.</p>
<h4 id="linear-classifier">Linear Classifier</h4>
<p>Use a simple linear classifier as a baseline:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression

clf <span style="color:#f92672">=</span> LogisticRegression(C<span style="color:#f92672">=</span><span style="color:#ae81ff">30.0</span>, class_weight<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;balanced&#39;</span>, solver<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;newton-cg&#39;</span>, 
                         multi_class<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;multinomial&#39;</span>, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">40</span>)
clf<span style="color:#f92672">.</span>fit(X_train_counts, y_train)

y_predicted_counts <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict(X_test_counts)
</code></pre></div><p>And use <code>sklearn.metrics</code> matric to measure the peformance:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score, f1_score, precision_score, recall_score, classification_report

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_metrics</span>(y_test, y_predicted):  
    <span style="color:#75715e"># true positives / (true positives+false positives)</span>
    precision <span style="color:#f92672">=</span> precision_score(y_test, y_predicted, pos_label<span style="color:#f92672">=</span>None,
                                    average<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;weighted&#39;</span>)             
    <span style="color:#75715e"># true positives / (true positives + false negatives)</span>
    recall <span style="color:#f92672">=</span> recall_score(y_test, y_predicted, pos_label<span style="color:#f92672">=</span>None,
                              average<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;weighted&#39;</span>)
    
    <span style="color:#75715e"># harmonic mean of precision and recall</span>
    f1 <span style="color:#f92672">=</span> f1_score(y_test, y_predicted, pos_label<span style="color:#f92672">=</span>None, average<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;weighted&#39;</span>)
    
    <span style="color:#75715e"># true positives + true negatives/ total</span>
    accuracy <span style="color:#f92672">=</span> accuracy_score(y_test, y_predicted)
    <span style="color:#66d9ef">return</span> accuracy, precision, recall, f1
</code></pre></div><p>We got accuracy of <code>0.761</code> and f1 score of <code>0.759</code> for a simple linear classifier. Not bad. This model is very simple to train and we can easily extract the most important features.</p>
<h4 id="confusing-matrix">Confusing matrix</h4>
<p>One of the most useful tool is the confusing matrix where we can have in-depth vision of where the model got wrong.</p>
<div style="text-align: center;">
    <img src="/images/confusion_matrix.png" alt=""  style="width: 550px;" />
    <p style="font-size: 15px;"></p>
</div>
<br />
<p>As we can see, the model predicts 25% false negative, which mean it predicts &ldquo;Irrelevant&rdquo; when in fact it was a &ldquo;Disaster&rdquo;. False positive is not desirable in this problem because it gives the authority less time to prepare when in fact there is a disaster coming in.</p>
<p>Some extra visualizations in the notebook, most notably most important words that the classifier uses to determine the class.</p>
<h4 id="tfidf-bag-of-words">TFIDF Bag of Words</h4>
<p>We use a TF-IDF score (Term Frequency, Inverse Document Frequency) on top of our Bag of Words model. TF-IDF weighs words by how rare they are in our dataset, discounting words that are too frequent and just add to the noise.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tfidf</span>(data):
    tfidf_vectorizer <span style="color:#f92672">=</span> TfidfVectorizer()

    train <span style="color:#f92672">=</span> tfidf_vectorizer<span style="color:#f92672">.</span>fit_transform(data)

    <span style="color:#66d9ef">return</span> train, tfidf_vectorizer

X_train_tfidf, tfidf_vectorizer <span style="color:#f92672">=</span> tfidf(X_train)
X_test_tfidf <span style="color:#f92672">=</span> tfidf_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</code></pre></div><div style="text-align: center;">
    <img src="/images/tfidf.png" alt=""  style="width: 600px;" />
    <p style="font-size: 15px;">IF-IDF visualization</p>
</div>
<br />
<p>Here the result is better. By leaving out many common words, it is
easier to separate the 2 groups. Now our linear classifier should be
able to do a better job. New accuracy is 76%, which is not a big
improvement from previous method.</p>
<div style="text-align: center;">
    <img src="/images/confusion_matrix_TFIDF.png" alt=""  style="width: 550px;" />
    <p style="font-size: 15px;"></p>
</div>
<br />
<h2 id="word2vec">Word2Vec</h2>
<p>Due to small number of tweets, it is unlikely that our model will pick up  the semantic meaning of words. It means that some tweets are classfied differently even when they contain very similiar words. To rectify this problem, we use a Word2Vec to capture the closeness between words and use in our model.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_average_word2vec</span>(tokens_list, vector, generate_missing<span style="color:#f92672">=</span>False, k<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>):
    <span style="color:#66d9ef">if</span> len(tokens_list)<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span>:
        <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>zeros(k)
    <span style="color:#66d9ef">if</span> generate_missing:
        vectorized <span style="color:#f92672">=</span> [vector[word] <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> vector <span style="color:#66d9ef">else</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(k) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokens_list]
    <span style="color:#66d9ef">else</span>:
        vectorized <span style="color:#f92672">=</span> [vector[word] <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> vector <span style="color:#66d9ef">else</span> np<span style="color:#f92672">.</span>zeros(k) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokens_list]
    length <span style="color:#f92672">=</span> len(vectorized)
    summed <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(vectorized, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
    averaged <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>divide(summed, length)
    <span style="color:#66d9ef">return</span> averaged

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_word2vec_embeddings</span>(vectors, clean_questions, generate_missing<span style="color:#f92672">=</span>False):
    embeddings <span style="color:#f92672">=</span> clean_questions[<span style="color:#e6db74">&#39;tokens&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: get_average_word2vec(x, vectors, 
                                                                                generate_missing<span style="color:#f92672">=</span>generate_missing))
    <span style="color:#66d9ef">return</span> list(embeddings)

embeddings <span style="color:#f92672">=</span> get_word2vec_embeddings(word2vec, clean_questions)
X_train_word2vec, X_test_word2vec, y_train_word2vec, y_test_word2vec <span style="color:#f92672">=</span> train_test_split(embeddings, list_labels, 
                                                                                        test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">40</span>)</code></pre></td></tr></table>
</div>
</div>
<p>As we see in line 10, we do average of all word2vec vectors of each word. Just this simple calculation give us a quite good representation the tweets, even though order is not taken into consideration. We graph the new average word2vec as below</p>
<div style="text-align: center;">
    <img src="/images/word2vec.png" alt=""  style="width: 600px;" />
    <p style="font-size: 15px;">Average word2vec</p>
</div>
<br />
<p>And the confusion matrix, new method has almost identical accuracy but is still a sligh improvement over all previous methods.</p>
<div style="text-align: center;">
    <img src="/images/word2vec_confusionmatrix.png" alt=""  style="width: 600px;" />
    <p style="font-size: 15px;">Average word2vec</p>
</div>
<br />
<h2 id="cnn-for-text-classification">CNN for text classification</h2>
<p>Convolutional Neural Network (CNN) model is better known in image classification but it can be used in text classification. Unlike the previous models where order is not taken into consideration, CNN can distinguish between &ldquo;Paul eats plants&rdquo; and &ldquo;Plants eat Paul&rdquo;</p>
<p>See more in part 2&hellip;</p>

</div>

  
<footer class='entry-footer'>
  <div class='container sep-before'><div class='last-updated'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
      <path d="M20 14.66V20a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h5.34" />
  <polygon points="18 2 22 6 12 16 8 16 8 12 18 2" />

</svg>
<span class='screen-reader-text'>Last updated: </span>
      <time class='entry-date' datetime='2020-11-06T02:45:03&#43;01:00'>2020, Nov 06</time>
    </div><div class='categories'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
    <path d="M22,19a2,2,0,0,1-2,2H4a2,2,0,0,1-2-2V5A2,2,0,0,1,4,3H9l2,3h9a2,2,0,0,1,2,2Z"/>

</svg>
<span class='screen-reader-text'>Categories: </span><a class='category' href='/categories/tutorial/'>Tutorial</a></div>
<div class='tags'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
  <path d="M20.59,13.41l-7.17,7.17a2,2,0,0,1-2.83,0L2,12V2H12l8.59,8.59A2,2,0,0,1,20.59,13.41Z"/>
  <line x1="7" y1="7" x2="7" y2="7"/>

</svg>
<span class='screen-reader-text'>Tags: </span><a class='tag' href='/tags/nlp/'>NLP</a>, <a class='tag' href='/tags/deep-learning/'>Deep Learning</a>, <a class='tag' href='/tags/machine-learning/'>Machine Learning</a></div>

  </div>
</footer>


</article>

<nav class='entry-nav'>
  <div class='container'><div class='prev-entry sep-before'>
      <a href='/posts/install-cuda-11-in-ubuntu/'>
        <span aria-hidden='true'><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
  <line x1="20" y1="12" x2="4" y2="12"/>
  <polyline points="10 18 4 12 10 6"/>

</svg>
 Previous</span>
        <span class='screen-reader-text'>Previous post: </span>Install Cuda 11 in Ubuntu</a>
    </div></div>
</nav>




      </main>

      <footer id='footer' class='footer'>
        <div class='container sep-before'><section class='widget widget-social_menu sep-after'><nav aria-label='Social Menu'>
    <ul><li>
        <a href='https://github.com/thanhluan001' target='_blank' rel='noopener me'>
          <span class='screen-reader-text'>Open Github account in new tab</span><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    
      <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>

</svg>
</a>
      </li><li>
        <a href='mailto:luan.pham0586@gmail.com' target='_blank' rel='noopener me'>
          <span class='screen-reader-text'>Contact via Email</span><svg class='icon' xmlns='http://www.w3.org/2000/svg' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline>
</svg>
</a>
      </li></ul>
  </nav>
</section><div class='copyright'>
  <p> &copy; 2020 Luan Pham </p>
</div>

        </div>
      </footer>

    </div>
  </div><script>window.__assets_js_src="/assets/js/"</script>

<script src='/assets/js/main.c3bcf2df.js'></script><script src='/js/custom.js'></script>

</body>

</html>

